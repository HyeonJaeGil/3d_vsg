{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import torch\n",
    "import open3d as o3d\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scan_dict(unformated_dict: Dict, attribute: str) -> Dict:\n",
    "    # Format raw dictionary of object nodes for all scenes\n",
    "    scan_list = unformated_dict[\"scans\"]\n",
    "    formatted_dict = {}\n",
    "    for scan in scan_list:\n",
    "        formatted_dict[scan[\"scan\"]] = scan[attribute]\n",
    "    return formatted_dict\n",
    "\n",
    "\n",
    "def format_sem_seg_dict(sem_seg_dict: Dict) -> Dict:\n",
    "    seg_list = sem_seg_dict[\"segGroups\"]\n",
    "    return seg_list\n",
    "    # return seg_list\n",
    "    # formatted_dict = {}\n",
    "    # for seg in seg_list:\n",
    "    #     formatted_dict[seg[\"id\"]] = seg\n",
    "    # return formatted_dict\n",
    "\n",
    "\n",
    "def get_dataset_files(scan_dir):\n",
    "    object_data = json.load(open(os.path.join(scan_dir, \"3DSSG\", \"objects.json\")))\n",
    "    relationship_data = json.load(open(os.path.join(scan_dir, \"3DSSG\", \"relationships.json\")))\n",
    "    objects_dict = format_scan_dict(object_data, \"objects\")\n",
    "    relationships_dict = format_scan_dict(relationship_data, \"relationships\")\n",
    "    return objects_dict, relationships_dict\n",
    "\n",
    "def get_semseg(scan_dir, scan_id):\n",
    "    sem_seg_data = json.load(open(os.path.join(scan_dir, \"semantic_segmentation_data\", scan_id, \"semseg.v2.json\")))\n",
    "    sem_seg_dict = format_sem_seg_dict(sem_seg_data)\n",
    "    return sem_seg_dict\n",
    "\n",
    "def get_annotated_ply(scan_dir, scan_id):\n",
    "    ply_path = os.path.join(scan_dir, \"semantic_segmentation_data\", scan_id, \"labels.instances.annotated.v2.ply\")\n",
    "    o3d_ply = o3d.io.read_point_cloud(ply_path)\n",
    "    return o3d_ply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ply_vertices(scan_dir, scan_id):\n",
    "    filename = os.path.join(scan_dir, \"semantic_segmentation_data\", scan_id, \"labels.instances.annotated.v2.ply\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Parse header to find vertex start\n",
    "    header_ended = False\n",
    "    vertex_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip() == \"end_header\":\n",
    "            header_ended = True\n",
    "            vertex_start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if not header_ended:\n",
    "        raise ValueError(\"Invalid PLY file: No 'end_header' found.\")\n",
    "\n",
    "    # Extract vertex data\n",
    "    vertices = []\n",
    "    for line in lines[vertex_start_idx:]:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) != 11:  # Ensure correct format\n",
    "            continue\n",
    "        x, y, z = map(float, tokens[:3])\n",
    "        r, g, b = map(int, tokens[3:6])\n",
    "        objectId = int(tokens[6])\n",
    "        globalId = int(tokens[7])\n",
    "        NYU40 = int(tokens[8])\n",
    "        Eigen13 = int(tokens[9])\n",
    "        RIO27 = int(tokens[10])\n",
    "\n",
    "        vertices.append([x, y, z, r, g, b, objectId, globalId, NYU40, Eigen13, RIO27])\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    vertices = np.array(vertices, dtype=np.float32)\n",
    "\n",
    "    # Group by objectId\n",
    "    grouped_data = defaultdict(lambda: {\"xyz\": [], \"color\": [], \"globalId\": [], \"NYU40\": [], \"Eigen13\": [], \"RIO27\": []})\n",
    "    \n",
    "    for v in vertices:\n",
    "        obj_id = int(v[6])\n",
    "        grouped_data[obj_id][\"xyz\"].append(v[:3])\n",
    "        grouped_data[obj_id][\"color\"].append(v[3:6])\n",
    "        grouped_data[obj_id][\"globalId\"].append(v[7])\n",
    "        grouped_data[obj_id][\"NYU40\"].append(v[8])\n",
    "        grouped_data[obj_id][\"Eigen13\"].append(v[9])\n",
    "        grouped_data[obj_id][\"RIO27\"].append(v[10])\n",
    "\n",
    "    # Convert lists to NumPy arrays for efficient processing\n",
    "    for obj_id in grouped_data:\n",
    "        grouped_data[obj_id][\"xyz\"] = np.array(grouped_data[obj_id][\"xyz\"], dtype=np.float32)\n",
    "        grouped_data[obj_id][\"color\"] = np.array(grouped_data[obj_id][\"color\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"globalId\"] = np.array(grouped_data[obj_id][\"globalId\"], dtype=np.uint16)\n",
    "        grouped_data[obj_id][\"NYU40\"] = np.array(grouped_data[obj_id][\"NYU40\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"Eigen13\"] = np.array(grouped_data[obj_id][\"Eigen13\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"RIO27\"] = np.array(grouped_data[obj_id][\"RIO27\"], dtype=np.uint8)\n",
    "    \n",
    "    # merge the array of color, globalId, NYU40, Eigen13, RIO27 to a single array if the values are the same\n",
    "    for obj_id in grouped_data:\n",
    "        color = grouped_data[obj_id][\"color\"]\n",
    "        globalId = grouped_data[obj_id][\"globalId\"]\n",
    "        NYU40 = grouped_data[obj_id][\"NYU40\"]\n",
    "        Eigen13 = grouped_data[obj_id][\"Eigen13\"]\n",
    "        RIO27 = grouped_data[obj_id][\"RIO27\"]\n",
    "        if np.all(color == color[0]):\n",
    "            color = grouped_data[obj_id][\"color\"][0]\n",
    "            grouped_data[obj_id][\"color_hex\"] = \"#{:02x}{:02x}{:02x}\".format(color[0], color[1], color[2])\n",
    "        if np.all(globalId == globalId[0]):\n",
    "            grouped_data[obj_id][\"globalId\"] = globalId[0]\n",
    "        if np.all(NYU40 == NYU40[0]):\n",
    "            grouped_data[obj_id][\"NYU40\"] = NYU40[0]\n",
    "        if np.all(Eigen13 == Eigen13[0]):\n",
    "            grouped_data[obj_id][\"Eigen13\"] = Eigen13[0]\n",
    "        if np.all(RIO27 == RIO27[0]):\n",
    "            grouped_data[obj_id][\"RIO27\"] = RIO27[0]\n",
    "\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_ply_vertices_faces(scan_dir, scan_id):\n",
    "    filename = os.path.join(scan_dir, \"semantic_segmentation_data\", scan_id, \"labels.instances.annotated.v2.ply\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Parse header\n",
    "    header_ended = False\n",
    "    vertex_lines = []\n",
    "    face_lines = []\n",
    "    vertex_count = 0\n",
    "    face_count = 0\n",
    "    reading_vertices = False\n",
    "    reading_faces = False\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        tokens = line.split()\n",
    "        \n",
    "        if line.startswith(\"element vertex\"):\n",
    "            vertex_count = int(tokens[-1])\n",
    "            reading_vertices = True\n",
    "        \n",
    "        elif line.startswith(\"element face\"):\n",
    "            face_count = int(tokens[-1])\n",
    "            reading_faces = True\n",
    "        \n",
    "        elif line.strip() == \"end_header\":\n",
    "            header_ended = True\n",
    "            vertex_start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if not header_ended:\n",
    "        raise ValueError(\"Invalid PLY file: No 'end_header' found.\")\n",
    "\n",
    "    print(vertex_count, face_count)\n",
    "\n",
    "    # Extract vertex data\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    \n",
    "    for line in lines[vertex_start_idx:]:\n",
    "        tokens = line.split()\n",
    "        \n",
    "        # Reading vertex elements\n",
    "        if reading_vertices and len(vertices) < vertex_count:\n",
    "            if len(tokens) != 11:\n",
    "                continue\n",
    "            x, y, z = map(float, tokens[:3])\n",
    "            r, g, b = map(int, tokens[3:6])\n",
    "            objectId = int(tokens[6])\n",
    "            globalId = int(tokens[7])\n",
    "            NYU40 = int(tokens[8])\n",
    "            Eigen13 = int(tokens[9])\n",
    "            RIO27 = int(tokens[10])\n",
    "\n",
    "            vertices.append([x, y, z, r, g, b, objectId, globalId, NYU40, Eigen13, RIO27])\n",
    "\n",
    "        # Switch to face parsing after vertex count is reached\n",
    "        elif reading_faces and len(faces) < face_count:\n",
    "            if len(tokens) < 4:  # Ensure valid face format\n",
    "                continue\n",
    "            face_vertex_count = int(tokens[0])  # First number is the vertex count\n",
    "            if face_vertex_count != 3:\n",
    "                raise ValueError(\"Only triangular faces are supported.\")\n",
    "            faces.append([int(tokens[1]), int(tokens[2]), int(tokens[3])])\n",
    "\n",
    "    # Convert vertex list to NumPy array\n",
    "    vertices = np.array(vertices, dtype=np.float32)\n",
    "\n",
    "    # Convert face list to NumPy array\n",
    "    faces = np.array(faces, dtype=np.int32)\n",
    "\n",
    "    # Grouping vertices by objectId for clustering\n",
    "    grouped_data = defaultdict(lambda: {\"xyz\": [], \"color\": [], \"globalId\": [], \"NYU40\": [], \"Eigen13\": [], \"RIO27\": []})\n",
    "    \n",
    "    for v in vertices:\n",
    "        obj_id = int(v[6])\n",
    "        grouped_data[obj_id][\"xyz\"].append(v[:3])\n",
    "        grouped_data[obj_id][\"color\"].append(v[3:6])\n",
    "        grouped_data[obj_id][\"globalId\"].append(v[7])\n",
    "        grouped_data[obj_id][\"NYU40\"].append(v[8])\n",
    "        grouped_data[obj_id][\"Eigen13\"].append(v[9])\n",
    "        grouped_data[obj_id][\"RIO27\"].append(v[10])\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    for obj_id in grouped_data:\n",
    "        grouped_data[obj_id][\"xyz\"] = np.array(grouped_data[obj_id][\"xyz\"], dtype=np.float32)\n",
    "        grouped_data[obj_id][\"color\"] = np.array(grouped_data[obj_id][\"color\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"globalId\"] = np.array(grouped_data[obj_id][\"globalId\"], dtype=np.uint16)\n",
    "        grouped_data[obj_id][\"NYU40\"] = np.array(grouped_data[obj_id][\"NYU40\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"Eigen13\"] = np.array(grouped_data[obj_id][\"Eigen13\"], dtype=np.uint8)\n",
    "        grouped_data[obj_id][\"RIO27\"] = np.array(grouped_data[obj_id][\"RIO27\"], dtype=np.uint8)\n",
    "\n",
    "    return grouped_data, vertices[:, :3], faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semseg_with_pointcloud(scan_dir, scan_id):\n",
    "    sem_seg_dict = get_semseg(scan_dir, scan_id)\n",
    "    ply_data = read_ply_vertices(scan_dir, scan_id)\n",
    "\n",
    "    # add xyz field in ply_data to sem_seg_dict\n",
    "    for key in ply_data:\n",
    "        object_id = key\n",
    "        matched_objects = [seg for seg in sem_seg_dict if seg[\"id\"] == object_id]\n",
    "        if len(matched_objects) == 0:\n",
    "            print(f\"Object {object_id} not found in semseg dict\")\n",
    "            \n",
    "            continue\n",
    "        object = matched_objects[0]\n",
    "        object[\"xyz\"] = ply_data[key][\"xyz\"]\n",
    "\n",
    "    return sem_seg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/Backup/Dataset/3d_vsg/data\"\n",
    "scan_dir = os.path.join(root, \"raw\")\n",
    "scans = json.load(open(os.path.join(scan_dir, \"3RScan.json\")))\n",
    "objects_dict, relationships_dict = get_dataset_files(scan_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_id = \"ddc737b3-765b-241a-9c35-6b7662c04fc9\"\n",
    "sem_seg_dict = get_semseg(scan_dir, scan_id)\n",
    "o3d_ply = get_annotated_ply(scan_dir, scan_id)\n",
    "ply_data = read_ply_vertices(scan_dir, scan_id)\n",
    "\n",
    "object_dict = objects_dict[scan_id]\n",
    "relationship_dict = relationships_dict[scan_id]\n",
    "\n",
    "# # among object_dict, find the element that has the same \"id\" as the key in ply_data\n",
    "# # print the attributes of the object\n",
    "# for key in ply_data:\n",
    "#     object_id = key\n",
    "#     matched_obj = [obj for obj in object_dict if int(obj[\"id\"]) == object_id]\n",
    "#     if len(matched_obj) > 0:\n",
    "#         matched_obj = matched_obj[0]\n",
    "\n",
    "#         # print the attributes of the object\n",
    "#         print(f\"Object Attributes: {matched_obj}\")\n",
    "\n",
    "#         # visualize the object with open3d using the xyz and color data\n",
    "#         pcd = o3d.geometry.PointCloud()\n",
    "#         pcd.points = o3d.utility.Vector3dVector(ply_data[key][\"xyz\"])\n",
    "#         pcd.colors = o3d.utility.Vector3dVector(ply_data[key][\"color\"] / 255.0)\n",
    "#         o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_seg_dict_with_pc = get_semseg_with_pointcloud(scan_dir, scan_id)\n",
    "for seg in sem_seg_dict_with_pc:\n",
    "    print(f\"Segment Attributes: {seg.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene_list(scene: Dict):\n",
    "    # Returns a list of scan IDs and relative transformation matrices for an entire scene\n",
    "    scan_id_set = [scene[\"reference\"]]\n",
    "    scan_tf_set = [np.eye(4)]\n",
    "    scan_changes = [[]]\n",
    "    changes = []\n",
    "    for follow_scan in scene[\"scans\"]:\n",
    "        scan_id_set.append(follow_scan[\"reference\"])\n",
    "        if \"transform\" in follow_scan.keys():\n",
    "            scan_tf_set.append(np.array(follow_scan[\"transform\"]).reshape((4, 4)).T)\n",
    "        else:\n",
    "            scan_tf_set.append(np.eye(4))\n",
    "        for change in follow_scan[\"rigid\"]:\n",
    "            if isinstance(change, int):\n",
    "                changes.append(change)\n",
    "            else:\n",
    "                changes.append(change[\"instance_reference\"])\n",
    "        scan_changes.append(changes.copy())\n",
    "\n",
    "    return scan_id_set, scan_tf_set, scan_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_id_set, scan_tf_set, scan_changes = get_scene_list(scans[1])\n",
    "\n",
    "print(scan_id_set)\n",
    "print(scan_tf_set)\n",
    "print(scan_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "def format_sem_seg_dict_orig(sem_seg_dict: Dict) -> Dict:\n",
    "    object_dict = {}\n",
    "    for object in sem_seg_dict[\"segGroups\"]:\n",
    "        object_dict[object[\"id\"]] = object[\"obb\"][\"centroid\"]\n",
    "\n",
    "    return object_dict\n",
    "\n",
    "\n",
    "def build_scene_graph(nodes_dict: Dict, edges_dict: Dict, scan_id: str, scan_dir: str, graph_out=False) -> Tuple:\n",
    "    # Returns a scene graph from raw data, including:\n",
    "    #   - Nodes: objects with relevant attributes\n",
    "    #   = Edges: relationships between objects\n",
    "\n",
    "    # Extract objects in scan\n",
    "    if scan_id not in nodes_dict.keys() or scan_id not in edges_dict.keys():\n",
    "        return None, None, None\n",
    "\n",
    "    # Extract position information from Semantic Segmentation results\n",
    "    scan_sem_seg_file = os.path.join(scan_dir, \"semantic_segmentation_data\", scan_id, \"semseg.v2.json\")\n",
    "    if os.path.isfile(scan_sem_seg_file):\n",
    "        semantic_seg = json.load(open(scan_sem_seg_file))\n",
    "        object_pos_list = format_sem_seg_dict_orig(semantic_seg)\n",
    "    else:\n",
    "        print(f\"No Semantic Segmentation File Available for {scan_id}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Reformat node dictionary, include only relevant attributes, and add location\n",
    "    nodes = nodes_dict[scan_id]\n",
    "    input_node_list = []\n",
    "    for node in nodes:\n",
    "        node_copy = node.copy()\n",
    "        id = int(node[\"id\"])\n",
    "        att_dict = {\"label\": node_copy.pop(\"label\", None), \"affordances\": node_copy.pop(\"affordances\", None),\n",
    "                    \"attributes\": node_copy.pop(\"attributes\", None), \"global_id\": node_copy.pop(\"global_id\", None),\n",
    "                    \"color\": node_copy.pop(\"ply_color\", None)}\n",
    "\n",
    "        if object_pos_list is not None:\n",
    "            att_dict[\"attributes\"][\"location\"] = torch.tensor(np.clip(object_pos_list[id], -100, 100)).to(torch.float32)\n",
    "\n",
    "        att_dict[\"attributes\"].pop(\"lexical\", None)\n",
    "        input_node_list.append((id, att_dict))\n",
    "\n",
    "    # Extract edges from raw data\n",
    "    edges = edges_dict[scan_id]\n",
    "\n",
    "    # Can output a networkx Graph object for visualization purposes\n",
    "    if graph_out:\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(input_node_list)\n",
    "        for edge in edges:\n",
    "            graph.add_edge(edge[0], edge[1])\n",
    "    else:\n",
    "        graph = None\n",
    "\n",
    "    return graph, input_node_list, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, nodes, edges = build_scene_graph(objects_dict, relationships_dict, scan_id, scan_dir, graph_out=True)\n",
    "\n",
    "# visualize the scene graph\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw(graph, with_labels=True, pos=nx.spring_layout(graph))\n",
    "plt.show()\n",
    "\n",
    "print(nodes[0][1].keys())\n",
    "print(nodes[0][1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan in scans:\n",
    "    for k, v in scan.items():\n",
    "        print(k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in objects_dict.items():\n",
    "    print(key, \"total objects:\", len(value))\n",
    "    for obj in value:\n",
    "        new_value = {}\n",
    "        for k, v in obj.items():\n",
    "            if k in {\"ply_color\", \"label\", \"affordances\", \"id\", \"global_id\", \"attributes\"}:\n",
    "                new_value[k] = v\n",
    "        print(new_value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in relationships_dict.items():\n",
    "    print(key)\n",
    "    for rel in value:\n",
    "        print(rel)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = scans[0]\n",
    "ref_scan_id = scan[\"reference\"]\n",
    "rescan_ids = scan[\"scans\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
